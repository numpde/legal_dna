{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW07: Parsing\n",
    "\n",
    "Remember that these homework work as a completion grade. **You can skip one section of this homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bugs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           label                                            title  \\\n",
       "40739   sci/tech                          First class to the moon   \n",
       "105532  sci/tech                          Amazon #39;s Holiday Pi   \n",
       "45004   sci/tech       Will historic flight launch space tourism?   \n",
       "71894      world                Thais Drop Peace Bombs On Muslims   \n",
       "11970   business  U.S. Economy Grows at Slower Pace Than Expected   \n",
       "\n",
       "                                                     lead  \\\n",
       "40739   London - British airline magnate Richard Brans...   \n",
       "105532  Leave it to Amazon.com (Nasdaq: AMZN). Apparen...   \n",
       "45004   Regardless, space competitions are poised to b...   \n",
       "71894   (CBS) Millions of folded paper cranes fluttere...   \n",
       "11970   Struggling under the weight of a bloated trade...   \n",
       "\n",
       "                                                     text  \n",
       "40739   First class to the moon London - British airli...  \n",
       "105532  Amazon #39;s Holiday Pi Leave it to Amazon.com...  \n",
       "45004   Will historic flight launch space tourism? Reg...  \n",
       "71894   Thais Drop Peace Bombs On Muslims (CBS) Millio...  \n",
       "11970   U.S. Economy Grows at Slower Pace Than Expecte...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>title</th>\n      <th>lead</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>40739</th>\n      <td>sci/tech</td>\n      <td>First class to the moon</td>\n      <td>London - British airline magnate Richard Brans...</td>\n      <td>First class to the moon London - British airli...</td>\n    </tr>\n    <tr>\n      <th>105532</th>\n      <td>sci/tech</td>\n      <td>Amazon #39;s Holiday Pi</td>\n      <td>Leave it to Amazon.com (Nasdaq: AMZN). Apparen...</td>\n      <td>Amazon #39;s Holiday Pi Leave it to Amazon.com...</td>\n    </tr>\n    <tr>\n      <th>45004</th>\n      <td>sci/tech</td>\n      <td>Will historic flight launch space tourism?</td>\n      <td>Regardless, space competitions are poised to b...</td>\n      <td>Will historic flight launch space tourism? Reg...</td>\n    </tr>\n    <tr>\n      <th>71894</th>\n      <td>world</td>\n      <td>Thais Drop Peace Bombs On Muslims</td>\n      <td>(CBS) Millions of folded paper cranes fluttere...</td>\n      <td>Thais Drop Peace Bombs On Muslims (CBS) Millio...</td>\n    </tr>\n    <tr>\n      <th>11970</th>\n      <td>business</td>\n      <td>U.S. Economy Grows at Slower Pace Than Expected</td>\n      <td>Struggling under the weight of a bloated trade...</td>\n      <td>U.S. Economy Grows at Slower Pace Than Expecte...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "N = 10000 # # how many datapoints (sentences) to use\n",
    "df = pd.read_csv('train.zip', names=[\"label\", \"title\", \"lead\"])\n",
    "df[\"label\"] = df[\"label\"].map({1: \"world\", 2: \"sport\", 3: \"business\", 4: \"sci/tech\"}) \n",
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
    "df = df.sample(n=N, random_state=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "87539    (Condo, Pandemonium, Nothing, makes, New, York...\n",
       "69508    (A, Quiet, Struggle, for, the, Conservationist...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "df.text.sample(n=2).apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the corpus using spacy or load the pre-processed corpus\n",
    "df = df.assign(prepro=df.text.apply(nlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('class', 'announce'), ('branson', 'announce')]"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "def extract_subject_verb_pairs(sent):\n",
    "    subjs = [w for w in sent if w.dep_ == \"nsubj\"]\n",
    "    pairs = [(w.lemma_.lower(), w.head.lemma_.lower()) for w in subjs]\n",
    "    return pairs\n",
    "\n",
    "## extract the subject-verbs pairs and print the result for the first document\n",
    "sv_pairs = df.prepro.apply(extract_subject_verb_pairs)\n",
    "first(sv_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "it        be      270\n",
       "official  say     166\n",
       "he        be      101\n",
       "company   say      82\n",
       "that      be       76\n",
       "group     say      43\n",
       "they      be       39\n",
       "this      be       38\n",
       "profit    rise     38\n",
       "police    say      37\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "## create a list ranking the most common pairs and print the first 10 items\n",
    "pd.Series(Counter(sum(sv_pairs, []))).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "kill      people       76\n",
       "score     point        44\n",
       "take      lead         32\n",
       "win       39;t         28\n",
       "file      lawsuit      26\n",
       "reach     agreement    26\n",
       "cut       job          25\n",
       "announce  plan         22\n",
       "hit       homer        22\n",
       "pay       million      21\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "## do the same for verbs-object pairs ('dobj')\n",
    "\n",
    "def extract(sent):\n",
    "    x = [w for w in sent if w.dep_ == \"dobj\"]\n",
    "    p = [(w.head.lemma_.lower(), w.lemma_.lower()) for w in x]\n",
    "    return p\n",
    "\n",
    "pd.Series(Counter(df.prepro.apply(extract).sum())).nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "third         quarter      151\n",
       "next          year         119\n",
       "last          week         111\n",
       "              night         78\n",
       "open          source        75\n",
       "first         time          75\n",
       "chief         executive     69\n",
       "last          year          67\n",
       "mobile        phone         65\n",
       "presidential  election      53\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "## do the same for adjectives-nouns pairs ('amod')\n",
    "\n",
    "def extract(sent):\n",
    "    x = [w for w in sent if w.dep_ == \"amod\"]\n",
    "    p = [(w.lemma_.lower(), w.head.lemma_.lower()) for w in x]\n",
    "    return p\n",
    "\n",
    "pd.Series(Counter(df.prepro.apply(extract).sum())).nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring cross label dependencies (Skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO extract all the subject-verbs and verbs-object pairs for the verb \"win\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO for each label create a list ranking the most common subject-verbs pairs and one for the most common verbs-object pairs\n",
    "##TODO print the 10 most common pairs for each of the two lists for the labels \"sport\" and \"business\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38564bitvenvb5ce6a286a0a4e09a12406ae40e03074",
   "display_name": "Python 3.8.5 64-bit ('venv')"
  },
  "metadata": {
   "interpreter": {
    "hash": "88f42fa326d64d7433b6bf2a90e18fa8adc33f6e5abd7b8bafe6e492118b07cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}